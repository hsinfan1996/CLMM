Fit halo mass to shear profile: 1. ideal data
=============================================

*the LSST-DESC CLMM team*

This notebook demonstrates how to use ``clmm`` to estimate a WL halo
mass of a galaxy cluster in the ideal case: i) all galaxies on a single
source plane, ii) no redshift errors, iii) no shape noise. The steps
below correspond to: - Setting things up, with the proper imports. -
Generating a ideal mock dataset. - Computing the binned reduced
tangential shear profile, for two different binning scheme. - Setting up
the model to be fitted to the data. - Perform a simple fit using
``scipy.optimize.basinhopping`` and visualize the results.

Setup
-----

First, we import some standard packages.

.. code:: ipython3

    try: import clmm
    except:
        import notebook_install
        notebook_install.install_clmm_pipeline(upgrade=False)
        import clmm
    import numpy as np
    import matplotlib.pyplot as plt
    
    from numpy import random

Next, we import ``clmm``\ ’s core modules.

.. code:: ipython3

    import clmm
    import clmm.dataops as da
    import clmm.galaxycluster as gc
    import clmm.theory as theory
    from clmm import Cosmology

Make sure we know which version we’re using

.. code:: ipython3

    clmm.__version__




.. parsed-literal::

    '0.9.0'



We then import a support modules for a specific data sets. ``clmm``
includes support modules that enable the user to generate mock data in a
format compatible with ``clmm``. We also provide support modules for
processing other specific data sets for use with ``clmm``. Any existing
support module can be used as a template for creating a new support
module for another data set. If you do make such a support module,
please do consider making a pull request so we can add it for others to
use.

Making mock data
----------------

.. code:: ipython3

    from clmm.support import mock_data as mock

.. code:: ipython3

    np.random.seed(11)

To create mock data, we need to define a true cosmology.

.. code:: ipython3

    mock_cosmo = Cosmology(H0 = 70.0, Omega_dm0 = 0.27 - 0.045, Omega_b0 = 0.045, Omega_k0 = 0.0)

We now set some parameters for a mock galaxy cluster.

.. code:: ipython3

    cosmo = mock_cosmo
    cluster_id = "Awesome_cluster"
    cluster_m = 1.e15 # M200,m [Msun]
    cluster_z = 0.3
    src_z = 0.8
    concentration = 4
    ngals = 10000
    cluster_ra = 0.0
    cluster_dec = 0.0

Then we use the ``mock_data`` support module to generate a new galaxy
catalog.

.. code:: ipython3

    ideal_data = mock.generate_galaxy_catalog(cluster_m, cluster_z, concentration,
                                              cosmo, src_z, ngals=ngals)

This galaxy catalog is then converted to a ``clmm.GalaxyCluster``
object.

.. code:: ipython3

    gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec,
                                   cluster_z, ideal_data)

A ``clmm.GalaxyCluster`` object can be pickled and saved for later use.

.. code:: ipython3

    gc_object.save('mock_GC.pkl')

Any saved ``clmm.GalaxyCluster`` object may be read in for analysis.

.. code:: ipython3

    cl = clmm.GalaxyCluster.load('mock_GC.pkl')
    print("Cluster info = ID:", cl.unique_id, "; ra:", cl.ra, "; dec:", cl.dec,
          "; z_l :", cl.z)
    print("The number of source galaxies is :", len(cl.galcat))
    
    ra_l = cl.ra
    dec_l = cl.dec
    z = cl.z
    e1 = cl.galcat['e1']
    e2 = cl.galcat['e2']
    ra_s = cl.galcat['ra']
    dec_s = cl.galcat['dec']
    z_s = cl.galcat['z']


.. parsed-literal::

    Cluster info = ID: Awesome_cluster ; ra: 0.0 ; dec: 0.0 ; z_l : 0.3
    The number of source galaxies is : 10000


We can visualize the distribution of galaxies on the sky.

.. code:: ipython3

    fsize = 15
    
    fig = plt.figure(figsize=(10, 6))
    hb = fig.gca().hexbin(ra_s, dec_s, gridsize=50)
    
    cb = fig.colorbar(hb)
    cb.set_label('Number of sources in bin', fontsize=fsize)
    
    plt.gca().set_xlabel(r'$\Delta RA$', fontsize=fsize)
    plt.gca().set_ylabel(r'$\Delta Dec$', fontsize=fsize)
    plt.gca().set_title('Source Galaxies', fontsize=fsize)
    
    plt.show()



.. image:: Example1_Fit_Halo_Mass_to_Shear_Catalog_files/Example1_Fit_Halo_Mass_to_Shear_Catalog_25_0.png


``clmm`` separates cosmology-dependent and cosmology-independent
functionality.

Deriving observables
--------------------

We first demonstrate a few of the procedures one can perform on data
without assuming a cosmology.

Computing shear
~~~~~~~~~~~~~~~

``clmm.dataops.compute_tangential_and_cross_components`` calculates the
tangential and cross shears for each source galaxy in the cluster.

.. code:: ipython3

    theta, g_t, g_x = da.compute_tangential_and_cross_components(ra_l, dec_l, ra_s, dec_s, e1, e2, geometry="flat")

We can visualize the shear field at each galaxy location.

.. code:: ipython3

    fig = plt.figure(figsize=(10, 6))
    
    fig.gca().loglog(theta, g_t, '.')
    plt.ylabel("reduced shear", fontsize=fsize)
    plt.xlabel("angular distance [rad]", fontsize=fsize)




.. parsed-literal::

    Text(0.5, 0, 'angular distance [rad]')




.. image:: Example1_Fit_Halo_Mass_to_Shear_Catalog_files/Example1_Fit_Halo_Mass_to_Shear_Catalog_32_1.png


Radially binning the data
~~~~~~~~~~~~~~~~~~~~~~~~~

Here we compare the reconstructed mass under two different bin
definitions.

Note binning would cause fitted mass to be slightly larger than input
mass. The reason is that g(r), the tangential reduced shear along
cluster radius, is a convex function – the function value after binning
would be larger, but the bias becomes smaller as bin number increases.

.. code:: ipython3

    bin_edges1 = da.make_bins(0.01, 3.7, 50)
    bin_edges2 = da.make_bins(0.01, 3.7, 10)

``clmm.dataops.make_radial_profile`` evaluates the average shear of the
galaxy catalog in bins of radius.

.. code:: ipython3

    res1 = da.make_radial_profile(
        [g_t, g_x, z_s], theta, "radians", "Mpc", bins=bin_edges1, cosmo=cosmo, z_lens=z, include_empty_bins=False)
    res2 = da.make_radial_profile(
        [g_t, g_x, z_s], theta, "radians", "Mpc", bins=bin_edges2, cosmo=cosmo, z_lens=z, include_empty_bins=False)

Note that we set ``include_empty_bins=False`` explicitly here even
though it is the default behavior. Setting the argument to ``True``
would also return empty bins (that is, bins with *at most one* data
point in them), which would have to be excluded manually when fitting,
though it might be useful e.g., when combining datasets. To clarify the
behavior, consider the following comparison:

.. code:: ipython3

    res_with_empty = da.make_radial_profile(
        [g_t, g_x, z_s], theta, "radians", "Mpc", bins=1000, cosmo=cosmo, z_lens=z, include_empty_bins=True)
    # this is the default behavior
    res_without_empty = da.make_radial_profile(
        [g_t, g_x, z_s], theta, "radians", "Mpc", bins=1000, cosmo=cosmo, z_lens=z, include_empty_bins=False)
    res_with_empty['n_src'].size, res_without_empty['n_src'].size




.. parsed-literal::

    (1000, 892)



i.e., 108 bins have fewer than two sources in them and are excluded by
default (when setting the random seed to 11).

For later use, we’ll define some variables for the binned radius and
tangential shear.

.. code:: ipython3

    gt_profile1 = res1['p_0']
    r1 = res1['radius']
    z1 = res1['p_2']
    
    gt_profile2 = res2['p_0']
    r2 = res2['radius']
    z2 = res2['p_2']

We visualize the radially binned shear for our mock galaxies.

.. code:: ipython3

    fig = plt.figure(figsize=(10, 6))
    
    fig.gca().loglog(r1, gt_profile1, '.', label='50 bins')
    fig.gca().loglog(r2, gt_profile2, '+', markersize=15, label='10 bins')
    plt.legend(fontsize=fsize)
    
    plt.gca().set_title(r'Binned shear of source galaxies', fontsize=fsize)
    plt.gca().set_xlabel(r'$r\;[Mpc]$', fontsize=fsize)
    plt.gca().set_ylabel(r'$g_t$', fontsize=fsize)




.. parsed-literal::

    Text(0, 0.5, '$g_t$')




.. image:: Example1_Fit_Halo_Mass_to_Shear_Catalog_files/Example1_Fit_Halo_Mass_to_Shear_Catalog_44_1.png


You can also run ``make_radial_profile`` direct on a
``clmm.GalaxyCluster`` object.

.. code:: ipython3

    cl.compute_tangential_and_cross_components() # You need to add the shear components first
    cl.make_radial_profile("Mpc", bins=1000, cosmo=cosmo, include_empty_bins=False)
    pass

After running ``clmm.GalaxyCluster.make_radial_profile`` object, the
object acquires the ``clmm.GalaxyCluster.profile`` attribute.

.. code:: ipython3

    for n in cl.profile.colnames: cl.profile[n].format = "%6.3e"
    cl.profile.pprint(max_width=-1)


.. parsed-literal::

    radius_min   radius  radius_max     gt      gt_err      gx       gx_err      z       z_err     n_src  
    ---------- --------- ---------- --------- --------- ---------- --------- --------- --------- ---------
     1.929e-02 2.182e-02  2.490e-02 1.691e-01 4.808e-03 -2.168e-19 1.533e-19 8.000e-01 0.000e+00 2.000e+00
     4.172e-02 4.415e-02  4.733e-02 1.349e-01 7.322e-05  0.000e+00 9.813e-18 8.000e-01 0.000e+00 2.000e+00
     5.855e-02 6.252e-02  6.416e-02 1.220e-01 2.593e-04  0.000e+00 0.000e+00 8.000e-01 0.000e+00 2.000e+00
     1.595e-01 1.611e-01  1.651e-01 9.199e-02 7.327e-05  3.469e-18 2.453e-18 8.000e-01 0.000e+00 2.000e+00
     1.931e-01 1.937e-01  1.987e-01 8.635e-02 3.066e-05  0.000e+00 0.000e+00 8.000e-01 0.000e+00 2.000e+00
     2.100e-01 2.141e-01  2.156e-01 8.328e-02 9.241e-05 -6.939e-18 4.907e-18 8.000e-01 0.000e+00 2.000e+00
     2.156e-01 2.186e-01  2.212e-01 8.263e-02 1.109e-04  0.000e+00 0.000e+00 8.000e-01 6.410e-17 3.000e+00
     2.324e-01 2.357e-01  2.380e-01 8.029e-02 8.050e-05 -8.999e-18 6.363e-18 8.000e-01 0.000e+00 2.000e+00
     2.604e-01 2.644e-01  2.660e-01 7.669e-02 1.136e-05  8.457e-18 5.980e-18 8.000e-01 0.000e+00 2.000e+00
     2.773e-01 2.800e-01  2.829e-01 7.488e-02 4.569e-05 -1.735e-18 2.877e-18 8.000e-01 0.000e+00 4.000e+00
           ...       ...        ...       ...       ...        ...       ...       ...       ...       ...
     5.386e+00 5.390e+00  5.392e+00 5.314e-03 1.168e-06  5.557e-19 3.929e-19 8.000e-01 0.000e+00 2.000e+00
     5.397e+00 5.399e+00  5.403e+00 5.302e-03 7.397e-07  9.035e-21 7.377e-21 8.000e-01 6.410e-17 3.000e+00
     5.420e+00 5.423e+00  5.425e+00 5.270e-03 1.024e-06 -3.975e-19 3.136e-19 8.000e-01 6.410e-17 3.000e+00
     5.425e+00 5.430e+00  5.431e+00 5.261e-03 1.138e-06  4.066e-20 9.583e-21 8.000e-01 0.000e+00 2.000e+00
     5.437e+00 5.439e+00  5.442e+00 5.248e-03 9.058e-07 -1.355e-20 4.121e-19 8.000e-01 0.000e+00 4.000e+00
     5.448e+00 5.451e+00  5.453e+00 5.232e-03 6.448e-07 -6.776e-21 5.868e-21 8.000e-01 0.000e+00 4.000e+00
     5.459e+00 5.461e+00  5.465e+00 5.220e-03 1.021e-06 -2.317e-18 1.639e-18 8.000e-01 0.000e+00 2.000e+00
     5.470e+00 5.471e+00  5.476e+00 5.206e-03 8.014e-07  1.694e-21 1.198e-21 8.000e-01 0.000e+00 2.000e+00
     5.504e+00 5.508e+00  5.509e+00 5.159e-03 1.049e-06  7.906e-21 7.879e-21 8.000e-01 6.410e-17 3.000e+00
     5.509e+00 5.511e+00  5.515e+00 5.154e-03 7.874e-07  6.776e-21 4.792e-21 8.000e-01 0.000e+00 2.000e+00
     5.616e+00 5.621e+00  5.622e+00 5.015e-03 2.005e-08  4.235e-21 1.797e-21 8.000e-01 0.000e+00 2.000e+00
    Length = 892 rows


Modeling the data
-----------------

We next demonstrate a few of the procedures one can perform once a
cosmology has been chosen.

Choosing a halo model
~~~~~~~~~~~~~~~~~~~~~

``clmm.theory.predict_reduced_tangential_shear`` supports various
parametric halo profile functions, including ``nfw``. ``clmm.theory``
works in units of :math:`Mpc/h`, whereas the data is
cosmology-independent, with units of :math:`Mpc`.

.. code:: ipython3

    def nfw_to_shear_profile(logm, profile_info):
        [r, gt_profile, z_src_rbin] = profile_info
        m = 10.**logm
        gt_model = clmm.compute_reduced_tangential_shear(r,
                                                         m, concentration,
                                                         cluster_z, z_src_rbin, cosmo,
                                                         delta_mdef=200,
                                                         halo_profile_model='nfw')
        return sum((gt_model - gt_profile)**2)

Fitting a halo mass
~~~~~~~~~~~~~~~~~~~

We optimize to find the best-fit mass for the data under the two radial
binning schemes.

.. code:: ipython3

    from clmm.support.sampler import samplers

Note: The samplers[‘minimize’] is a local optimization function, so it
does not guarantee to give consistent results (logm_est1 and logm_est2)
for all logm_0, which is dependent on the np.random.seed(#) set
previously. Some choices of np.random.seed(#) (e.g. set # to 1) will
output a logm_0 that leads to a much larger logm_est and thus a
misbehaving best-fit model. In contrast, the samplers[‘basinhopping’] is
a global optimization function, which can give stable results regardless
of the initial guesses, logm_0. Since its underlying method is the same
as the samplers[‘minimize’], the two functions take the same arguments.

.. code:: ipython3

    logm_0 = random.uniform(13., 17., 1)[0]
    
    #logm_est1 = samplers['minimize'](nfw_to_shear_profile, logm_0,args=[r1, gt_profile1, z1])
    logm_est1 = samplers['basinhopping'](nfw_to_shear_profile, logm_0,args=[r1, gt_profile1, z1])
    
    #logm_est2 = samplers['minimize'](nfw_to_shear_profile, logm_0,args=[r2, gt_profile2, z2])
    logm_est2 = samplers['basinhopping'](nfw_to_shear_profile, logm_0,args=[r2, gt_profile2, z2])
    
    m_est1 = 10.**logm_est1
    m_est2 = 10.**logm_est2
    
    print((m_est1, m_est2))


.. parsed-literal::

    (1019053679927366.2, 1060631028853672.4)


Next, we calculate the reduced tangential shear predicted by the two
models.

.. code:: ipython3

    rr = np.logspace(-2, np.log10(5), 100)
    
    gt_model1 = clmm.compute_reduced_tangential_shear(rr,
                                                      m_est1, concentration,
                                                      cluster_z, src_z, cosmo,
                                                      delta_mdef=200,
                                                      halo_profile_model='nfw')
    
    gt_model2 = clmm.compute_reduced_tangential_shear(rr,
                                                      m_est2, concentration,
                                                      cluster_z, src_z, cosmo,
                                                      delta_mdef=200,
                                                      halo_profile_model='nfw')

We visualize the two predictions of reduced tangential shear.

.. code:: ipython3

    fig = plt.figure(figsize=(10, 6))
    
    fig.gca().scatter(r1, gt_profile1, color='orange',
                      label='binned mock data 1, M_input = %.3e Msun/h' % cluster_m)
    fig.gca().plot(rr, gt_model1, color='orange',
                   label='best fit model 1, M_fit = %.3e' % m_est1)
    
    fig.gca().scatter(r2, gt_profile2, color='blue', alpha=0.5,
                      label='binned mock data 2, M_input = %.3e Msun/h' % cluster_m)
    fig.gca().plot(rr, gt_model2, color='blue', linestyle='--', alpha=0.5,
                   label='best fit model 2, M_fit = %.3e' % m_est2)
    
    plt.semilogx()
    plt.semilogy()
    
    plt.legend()
    plt.xlabel('R [Mpc]', fontsize=fsize)
    plt.ylabel('reduced tangential shear', fontsize=fsize)




.. parsed-literal::

    Text(0, 0.5, 'reduced tangential shear')




.. image:: Example1_Fit_Halo_Mass_to_Shear_Catalog_files/Example1_Fit_Halo_Mass_to_Shear_Catalog_61_1.png

